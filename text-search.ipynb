{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT user support\n",
    "\n",
    "> Semantic search enabled via GPT and context-specific responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "import openai\n",
    "\n",
    "# Authenticate with OpenAI API\n",
    "openai.api_key = \"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\" # \"API-Key\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Hallucination (lying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Create an account on Tapipy.\\n\\n2. Log in to your account and go to the “My Apps” page.\\n\\n3. Click on “Create New App” and enter the details of your app.\\n\\n4. Once your app is created, click on “Generate Token”.\\n\\n5. Enter the details of the token you want to generate and click “Generate”.\\n\\n6. Your token will be generated and displayed on the screen.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"How to generate a token using Tapipy\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ther is no website called \"Tapipy\" to create an account...all these are wrong!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcing GPT to not lie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: How to generate a token using Tapipy?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well....that was very helpful!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing Context to GPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What if we could provide GPT with some context so it can provide useful help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To generate a token using Tapipy, first import the Tapis class and create a Python object called t that points to the Tapis server using your TACC username and password. Then, use the t object to get tokens that will be used for authenticated function calls by calling the get_tokens() method. Finally, print the access token to use for authentication.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Context: \n",
    "Create an Tapis Client Object\n",
    "\n",
    "The first step in using the Tapis Python SDK, tapipy, is to create a Tapis Client object. First, import the Tapis class and create python object called t that points to the Tapis server using your TACC username and password. Do so by typing the following in a Python shell:\n",
    "\n",
    "# Import the Tapis object\n",
    "from tapipy.tapis import Tapis\n",
    "\n",
    "# Log into you the Tapis service by providing user/pass and url.\n",
    "t = Tapis(base_url='https://tacc.tapis.io',\n",
    "          username='your username',\n",
    "          password='your password')\n",
    "\n",
    "Generate a Token\n",
    "\n",
    "With the t object instantiated, we can exchange our credentials for an access token. In Tapis, you never send your username and password directly to the services; instead, you pass an access token which is cryptographically signed by the OAuth server and includes information about your identity. The Tapis services use this token to determine who you are and what you can do.\n",
    "\n",
    "    # Get tokens that will be used for authenticated function calls\n",
    "    t.get_tokens()\n",
    "    print(t.access_token.access_token)\n",
    "\n",
    "    Out[1]: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9...\n",
    "\n",
    "Note that the tapipy t object will store and pass your access token for you, so you don’t have to manually provide the token when using the tapipy operations. You are now ready to check your access to the Tapis APIs. It will expire though, after 4 hours, at which time you will need to generate a new token. If you are interested, you can create an OAuth client (a one-time setup step, like creating a TACC account) that can be used to generate access and refresh tokens. For simplicity, we are skipping that but if you are interested, check out the Tenancy and Authentication section.\n",
    "Q: How to generate a token using Tapipy?\n",
    "A:\n",
    "\"\"\"\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Create a word embedding as vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2262 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import markdown2\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Open the markdown file\n",
    "with open(\"actor.md\", \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use markdown2 to convert the markdown file to html\n",
    "html = markdown2.markdown(content)\n",
    "\n",
    "# Use BeautifulSoup to parse the html\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Initialize variables to store heading, subheading, and corresponding paragraphs\n",
    "headings = []\n",
    "paragraphs = []\n",
    "\n",
    "data = []\n",
    "\n",
    "MAX_WORDS = 500\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"count the number of tokens in a string\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Iterate through the tags in the soup\n",
    "for tag in soup.descendants:\n",
    "    # Check if the tag is a heading\n",
    "    if tag.name in [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]:\n",
    "        # When the next heading is encountered, print the heading, subheading, and corresponding paragraphs\n",
    "        if headings and paragraphs:\n",
    "            hdgs = \" \".join(headings)\n",
    "            para = \" \".join(paragraphs)\n",
    "            data.append([hdgs, para, count_tokens(para)])\n",
    "            headings = []\n",
    "            paragraphs = []\n",
    "        # Add to heading\n",
    "        headings.append(tag.text)\n",
    "    # Check if the tag is a paragraph\n",
    "    elif tag.name == \"p\":\n",
    "        paragraphs.append(tag.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataset and filter out any sections with fewer than 40 tokens, as those are unlikely to contain enough context to ask a good question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actors Introduction to Abaco What is Abaco</td>\n",
       "      <td>Abaco is an NSF-funded web service and distrib...</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Using Abaco</td>\n",
       "      <td>Abaco is in production and has been adopted by...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Getting Started</td>\n",
       "      <td>This Getting Started guide will walk you throu...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Creation and Software Installation Cre...</td>\n",
       "      <td>The main instance of the Abaco platform is hos...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create a Docker account</td>\n",
       "      <td>Docker is an open-source container runtime\\npr...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             heading  \\\n",
       "0         Actors Introduction to Abaco What is Abaco   \n",
       "1                                        Using Abaco   \n",
       "2                                    Getting Started   \n",
       "3  Account Creation and Software Installation Cre...   \n",
       "4                            Create a Docker account   \n",
       "\n",
       "                                             content  tokens  \n",
       "0  Abaco is an NSF-funded web service and distrib...     131  \n",
       "1  Abaco is in production and has been adopted by...      58  \n",
       "2  This Getting Started guide will walk you throu...      85  \n",
       "3  The main instance of the Abaco platform is hos...      77  \n",
       "4  Docker is an open-source container runtime\\npr...      55  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=[\"heading\", \"content\", \"tokens\"])\n",
    "df = df[df.tokens>40]\n",
    "df = df.reset_index().drop('index',axis=1) # reset index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL):\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_embedding = compute_doc_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vector_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actors Introduction to Abaco What is Abaco</td>\n",
       "      <td>Abaco is an NSF-funded web service and distrib...</td>\n",
       "      <td>131</td>\n",
       "      <td>[-0.008385769091546535, -0.01955496147274971, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Using Abaco</td>\n",
       "      <td>Abaco is in production and has been adopted by...</td>\n",
       "      <td>58</td>\n",
       "      <td>[-0.017907971516251564, -0.008049326948821545,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Getting Started</td>\n",
       "      <td>This Getting Started guide will walk you throu...</td>\n",
       "      <td>85</td>\n",
       "      <td>[-0.0068563916720449924, -0.010913005098700523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Account Creation and Software Installation Cre...</td>\n",
       "      <td>The main instance of the Abaco platform is hos...</td>\n",
       "      <td>77</td>\n",
       "      <td>[-0.0048550949431955814, -0.020554518327116966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create a Docker account</td>\n",
       "      <td>Docker is an open-source container runtime\\npr...</td>\n",
       "      <td>55</td>\n",
       "      <td>[-0.0035271041560918093, -0.03285187482833862,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             heading  \\\n",
       "0         Actors Introduction to Abaco What is Abaco   \n",
       "1                                        Using Abaco   \n",
       "2                                    Getting Started   \n",
       "3  Account Creation and Software Installation Cre...   \n",
       "4                            Create a Docker account   \n",
       "\n",
       "                                             content  tokens  \\\n",
       "0  Abaco is an NSF-funded web service and distrib...     131   \n",
       "1  Abaco is in production and has been adopted by...      58   \n",
       "2  This Getting Started guide will walk you throu...      85   \n",
       "3  The main instance of the Abaco platform is hos...      77   \n",
       "4  Docker is an open-source container runtime\\npr...      55   \n",
       "\n",
       "                                    vector_embedding  \n",
       "0  [-0.008385769091546535, -0.01955496147274971, ...  \n",
       "1  [-0.017907971516251564, -0.008049326948821545,...  \n",
       "2  [-0.0068563916720449924, -0.010913005098700523...  \n",
       "3  [-0.0048550949431955814, -0.020554518327116966...  \n",
       "4  [-0.0035271041560918093, -0.03285187482833862,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vector_embedding'] = pd.Series(vector_embedding)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Find the most similar document embeddings to the question embedding\n",
    "\n",
    "We embed the query strip and use it to find the most similar document sections. Since this is a small example, we store and search the embeddings locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "def order_documents_query_similarity(data, query_str, nres=3):\n",
    "    embedding = get_embedding(query_str, model=EMBEDDING_MODEL)\n",
    "    data['similarities'] = data.vector_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = data.sort_values('similarities', ascending=False).head(nres)\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most relevant document sections for the token is listed at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vector_embedding</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Get tokens that will be used for authenticated...</td>\n",
       "      <td>t.gettokens()\\n  print(t.accesstoken.access_to...</td>\n",
       "      <td>205</td>\n",
       "      <td>[-0.012254482135176659, -0.010697360150516033,...</td>\n",
       "      <td>0.828021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Create an Tapis Client Object</td>\n",
       "      <td>The first step in using the Tapis Python SDK, ...</td>\n",
       "      <td>69</td>\n",
       "      <td>[-0.006625453941524029, -0.005176678765565157,...</td>\n",
       "      <td>0.824937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Python with Tapipy</td>\n",
       "      <td>Setting up an Tapis object with token and API ...</td>\n",
       "      <td>502</td>\n",
       "      <td>[-0.015956224873661995, -0.0027807820588350296...</td>\n",
       "      <td>0.816858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              heading  \\\n",
       "10  Get tokens that will be used for authenticated...   \n",
       "7                       Create an Tapis Client Object   \n",
       "36                                 Python with Tapipy   \n",
       "\n",
       "                                              content  tokens  \\\n",
       "10  t.gettokens()\\n  print(t.accesstoken.access_to...     205   \n",
       "7   The first step in using the Tapis Python SDK, ...      69   \n",
       "36  Setting up an Tapis object with token and API ...     502   \n",
       "\n",
       "                                     vector_embedding  similarities  \n",
       "10  [-0.012254482135176659, -0.010697360150516033,...      0.828021  \n",
       "7   [-0.006625453941524029, -0.005176678765565157,...      0.824937  \n",
       "36  [-0.015956224873661995, -0.0027807820588350296...      0.816858  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = order_documents_query_similarity(df, \"How to generate a token using Tapipy\")\n",
    "res.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Add the most relevant document sections to the query prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question =  \"How to generate a token using Tapipy\"\n",
    "context = order_documents_query_similarity(df, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, df: pd.DataFrame, ncontents = 3) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "  \n",
    "    chosen_sections = []\n",
    "    chosen_section_len = 0\n",
    "\n",
    "    MAX_SECTION_LEN = 500\n",
    "    context = order_documents_query_similarity(df, question)\n",
    "    sources = []\n",
    "    for _, ctx in context.iterrows():\n",
    "        chosen_section_len += ctx.tokens\n",
    "        sources.append(ctx[\"heading\"])\n",
    "        if chosen_section_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(\" \" + ctx.content.replace(\"\\n\", \" \"))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return (header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\", sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don\\'t know.\"\\n\\nContext:\\n t.gettokens()   print(t.accesstoken.access_token) Out[1]: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9...   ``` Note that the tapipy t object will store and pass your access token for you, so you don\\\\\\'t have to manually provide the token when using the tapipy operations. You are now ready to check your access to the Tapis APIs. It will expire though, after 4 hours, at which time you will need to generate a new token. If you are interested, you can create an OAuth client (a one-time setup step, like creating a TACC account) that can be used to generate access and refresh tokens. For simplicity, we are skipping that but if you are interested, check out the Tenancy and Authentication section. The first step in using the Tapis Python SDK, tapipy, is to create a Tapis Client object. First, import the Tapis class and create python object called t that points to the Tapis server using your TACC username and password. Do so by typing the following in a Python shell: ``` python\\n\\n Q: How to generate a token using Tapipy\\n A:',\n",
       " ['Get tokens that will be used for authenticated function calls',\n",
       "  'Create an Tapis Client Object',\n",
       "  'Python with Tapipy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_prompt(question=\"How to generate a token using Tapipy\", df=df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Answer the user's question based on the context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 300,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}\n",
    "\n",
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    show_prompt: bool = False) -> str:\n",
    "    \n",
    "    prompt, sources = construct_prompt(\n",
    "        query,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return {\"answer \" : response[\"choices\"][0][\"text\"].strip(\" \\n\"), \"sources \" : sources}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original GPT without context - telling lies as it invents a new Tapipy website and App to generate a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Create an account on Tapipy.\\n\\n2. Log in to your account and go to the “My Apps” page.\\n\\n3. Click on “Create New App” and enter the details of your app.\\n\\n4. Once your app is created, click on “Generate Token”.\\n\\n5. Enter the details of the token you want to generate and click “Generate”.\\n\\n6. Your token will be generated and displayed on the screen.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"How to generate a token using Tapipy\"\n",
    "\n",
    "openai.Completion.create(prompt=prompt, temperature=0, max_tokens=300, model=COMPLETIONS_MODEL)[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you ask a question for which it can find a context! - It answers correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer ': 'Use the t.gettokens() command to generate a token using Tapipy.',\n",
       " 'sources ': ['Get tokens that will be used for authenticated function calls',\n",
       "  'Create an Tapis Client Object',\n",
       "  'Python with Tapipy']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"How to generate a token using Tapipy\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When it doesn't know...at least it is honest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer ': \"I don't know.\",\n",
       " 'sources ': ['Create an Tapis Client Object',\n",
       "  'Install the Tapis Python SDK',\n",
       "  'Python with Tapipy']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"How to access files using Tapipy\", df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and Read from Paraquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "# Convert from pandas to Arrow\n",
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "# Infer Arrow schema from pandas\n",
    "schema = pa.Schema.from_pandas(df)\n",
    "pq.write_table(table, \"tapis.parquet\", compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table(\"tapis.parquet\")\n",
    "# Convert back to pandas\n",
    "df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a15fe14c9164b2c84764451972c480ab7caecb14ffdaafbc4f746bd44fda90e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
